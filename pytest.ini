[tool:pytest]
# Pytest configuration for Trading Bot Test Suite

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Markers for test categorization
markers =
    live_trading: marks tests as live trading component tests (critical)
    risk_management: marks tests as risk management tests (critical)
    strategy: marks tests as strategy-related
    data_provider: marks tests as data provider tests
    integration: marks tests as integration tests (slower)
    slow: marks tests as slow running tests
    performance: marks tests that validate performance metrics
    timeout: mark test to fail if it runs longer than given seconds (use @pytest.mark.timeout(30))
    network: marks tests that require network access
    ml: marks tests related to machine learning models

# Test execution options
addopts = 
    -v
    --strict-markers
    --strict-config
    --tb=short
    --capture=no
    --disable-warnings

# Minimum version requirements
minversion = 6.0

# Configure test collection
# Note: collect_ignore is not supported in pytest.ini, use conftest.py instead

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Filterwarnings
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    # Add specific warnings to ignore here

# Test timeout (30 seconds per test)
timeout = 30

# Coverage options (when using pytest-cov)
# Uncomment these if using coverage
# addopts = --cov=ai-trading-bot --cov-report=term-missing --cov-report=html
# --cov-fail-under=85

[pytest]
markers =
    integration: marks tests as integration tests (slower)
    live_trading: marks tests that test live trading components
    risk_management: marks tests related to risk management
    strategy: marks tests related to strategy logic
    data_provider: marks tests related to data providers
    performance: marks tests that validate performance metrics
    timeout(duration): mark test to fail if it runs longer than given seconds
    slow: marks tests as slow (deselect with '-m "not slow"')